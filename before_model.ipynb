{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0f96f3f",
   "metadata": {},
   "source": [
    "### action 处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e198bb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#读取量化的参与意愿\n",
    "activity = pd.read_csv('./row_data/action_willingness.csv', index_col='enroll_id')\n",
    "\n",
    "#读取最初的\n",
    "data = pd.read_csv('./row_data/number_data.csv',\n",
    "                   index_col='enroll_id',\n",
    "                   usecols=[0, 21, 22, 23],\n",
    "                   )\n",
    "\n",
    "activity = pd.merge(data, activity, on='enroll_id', how='outer')\n",
    "\n",
    "activity.to_csv('./action_data_process/willingness_merge.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ad1a862",
   "metadata": {},
   "outputs": [],
   "source": [
    "activity = pd.read_csv('./action_data_process/willingness_merge.csv')\n",
    "del activity['enroll_id']\n",
    "activity.to_csv('./action_data_process/model_input_willingness.csv',index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e7b97b",
   "metadata": {},
   "source": [
    "### action划分训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a68a62dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69171\n",
      "72694\n"
     ]
    }
   ],
   "source": [
    "#只按照7：3，8：2的比例去划分\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.model_selection import KFold\n",
    "class DataSet():\n",
    "    def __init__(self, basedir):\n",
    "        self.basedir = basedir\n",
    "        read_dir = basedir + '/action_data_process/'\n",
    "        save_dir = basedir + '/action_data_process/'\n",
    "        data = pd.read_csv(read_dir + \"model_input_willingness.csv\")\n",
    "\n",
    "        self.record = data.set_index('username')\n",
    "        self.total_stu_list = list(set(self.record.index))\n",
    "        self.save_dir = save_dir\n",
    "\n",
    "    def get_train_test(self, test_ratio = 0.2):\n",
    "            train, test= split_record(self.record, test_ratio= test_ratio)\n",
    "            return train, test  # 这里划分了， index_loader里的id应该从这里取\n",
    "\n",
    "\n",
    "def split_record(record, test_ratio = 0.2):\n",
    "    total_stu_list = list(set(record.index))\n",
    "    train_data = [[], [], [], []]\n",
    "    test_data = [[], [], [], []]\n",
    "    for stu in total_stu_list:\n",
    "        stu_data = record.loc[stu, :]\n",
    "        stu_cour = np.array(stu_data['course_id'])\n",
    "        stu_truth = np.array((stu_data['truth']))\n",
    "        stu_activity = np.array(stu_data['willingness'])\n",
    "        length = len(stu_cour)\n",
    "\n",
    "    \n",
    "        index_list = list(range(length))\n",
    " \n",
    "        test_index = random.sample(index_list, math.ceil(length * test_ratio))\n",
    "\n",
    "        #剩下的所有为训练集\n",
    "        train_index = list(set(index_list) - set(test_index))\n",
    "\n",
    "        train_data[0].extend([stu] * len(train_index))\n",
    "        train_data[1].extend(stu_cour[train_index])\n",
    "        train_data[2].extend(stu_truth[train_index])\n",
    "        train_data[3].extend(stu_activity[train_index])\n",
    "\n",
    "\n",
    "        test_data[0].extend([stu] * len(test_index))\n",
    "        test_data[1].extend(stu_cour[test_index])\n",
    "        test_data[2].extend(stu_truth[test_index])\n",
    "        test_data[3].extend(stu_activity[test_index])\n",
    "\n",
    "    train = pd.DataFrame({'username': train_data[0], 'course_id': train_data[1],'truth': train_data[2],'willingness': train_data[3]},).set_index('username')\n",
    "    test = pd.DataFrame({'username': test_data[0], 'course_id': test_data[1], 'truth': test_data[2],'willingness': test_data[3]},).set_index('username')\n",
    "    return train, test\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # ----------基本参数--------------\n",
    "    basedir = 'D:/pythonProject/firstpaper/firstdata_process'\n",
    "    dataSet = DataSet(basedir)\n",
    "    save_dir = dataSet.save_dir\n",
    "    test_ratio = 0.2\n",
    "    train_data, test_data = dataSet.get_train_test(test_ratio= test_ratio)\n",
    "    print(len(train_data))\n",
    "    print(len(test_data))\n",
    "    train_data.to_csv(save_dir+'train_data_2.csv')\n",
    "    test_data.to_csv(save_dir+'test_data_2.csv')\n",
    "    # ----------基本参数--------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bac76983",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./action_data_process/train_data_2.csv')\n",
    "test_data = pd.read_csv('./action_data_process/test_data_2.csv')\n",
    "\n",
    "del train_data['truth']\n",
    "del test_data['truth']\n",
    "\n",
    "train_data.to_csv('./model_input_data/model_train_data_2.csv',index=0)\n",
    "test_data.to_csv('./model_input_data/model_test_data_2.csv',index=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04342090",
   "metadata": {},
   "source": [
    "### 利用action进行选课邻接矩阵处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93d2dc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1caa4119",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj2_data = pd.read_csv('./model_input_data/model_train_data_2.csv',usecols = [0,1])\n",
    "df = pd.crosstab(adj2_data.username,adj2_data.course_id)\n",
    "\n",
    "df.to_csv('./model_input_data/adjacency_2.csv',)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655a4f3e",
   "metadata": {},
   "source": [
    "### 利用action求聚合矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a3cda225",
   "metadata": {},
   "outputs": [],
   "source": [
    "martix_data = pd.read_csv('./model_input_data/model_train_data_2.csv',usecols = [0,1])\n",
    "row_data = pd.read_csv('./row_data/number_data.csv',usecols = [2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22])\n",
    "data = pd.merge(martix_data, row_data, on=['username','course_id'], how='inner')\n",
    "data.to_csv('./action_martix/train_data_2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67be2f2b",
   "metadata": {},
   "source": [
    "### 分别对用户和课程进行分类，用来求聚合矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "eebe2e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import csv\n",
    "result = {}\n",
    "if __name__ == '__main__':\n",
    "    switch = 0\n",
    "    header = []\n",
    "    with open(\"./action_martix/train_data_2.csv\") as f:\n",
    "        csv_reader = csv.reader(f)\n",
    "        for row in csv_reader:\n",
    "            if switch == 0:\n",
    "                header = row\n",
    "                switch = 1\n",
    "                continue\n",
    "            if row[1] not in result.keys():\n",
    "                result[row[1]] = []\n",
    "                result[row[1]].append(header)\n",
    "                result[row[1]].append(row)\n",
    "            else:\n",
    "                result[row[1]].append(row)\n",
    "        f.close()\n",
    "\n",
    "    for file_name in result.keys():\n",
    "        with open(\"./action_martix/martix_2_sort_user/\"+file_name+\".csv\", 'w', newline=\"\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerows(result[file_name])\n",
    "            f.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "41de2795",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "result = {}\n",
    "if __name__ == '__main__':\n",
    "    switch = 0\n",
    "    header = []\n",
    "    with open(\"./action_martix/train_data_2.csv\") as f:\n",
    "        csv_reader = csv.reader(f)\n",
    "        for row in csv_reader:\n",
    "            if switch == 0:\n",
    "                header = row\n",
    "                switch = 1\n",
    "                continue\n",
    "\n",
    "         \n",
    "            if row[2] not in result.keys():\n",
    "                result[row[2]] = []\n",
    "                result[row[2]].append(header)\n",
    "                result[row[2]].append(row)\n",
    "            else:\n",
    "                result[row[2]].append(row)\n",
    "        f.close()\n",
    "\n",
    "    for file_name in result.keys():\n",
    "        with open(\"./action_martix/martix_2_sort_course/\"+file_name+\".csv\", 'w', newline=\"\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerows(result[file_name])\n",
    "            f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ef650a",
   "metadata": {},
   "source": [
    "### 对行为求均值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "afe77598",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "input_path = './action_martix/martix_2_sort_user/*.csv'\n",
    "all_files = glob.glob(input_path)\n",
    "\n",
    "for file in all_files:\n",
    "    data_frame = pd.read_csv(file,\n",
    "                             index_col=None,\n",
    "                             # usecols=[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20],\n",
    "                             encoding='gbk')\n",
    "    key_cols = data_frame.keys().tolist()[3:22]\n",
    "    data_frame[key_cols] = data_frame[key_cols].apply(\n",
    "        lambda x: x.mean()\n",
    "    )\n",
    "\n",
    "    \n",
    "    file_name = file.split('\\\\')[-1]  \n",
    "    data_frame.to_csv('./action_martix/mean_2_sort_user/' + file_name, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4f3a64ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "input_path = './action_martix/martix_2_sort_course/*.csv'\n",
    "all_files = glob.glob(input_path)\n",
    "for file in all_files:\n",
    "    data_frame = pd.read_csv(file,\n",
    "                             index_col=None,\n",
    "                             # usecols=[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20],\n",
    "                             encoding='gbk')\n",
    "    key_cols = data_frame.keys().tolist()[3:22]\n",
    "    data_frame[key_cols] = data_frame[key_cols].apply(\n",
    "        lambda x: x.mean()\n",
    "    )\n",
    "    file_name = file.split('\\\\')[-1] \n",
    "    data_frame.to_csv('./action_martix/mean_2_sort_course/' + file_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566985c5",
   "metadata": {},
   "source": [
    "### 求聚合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dbeb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "input_path = './action_martix/mean_2_sort_user/*.csv'\n",
    "\n",
    "# glob.glob()函数将会匹配给定路径下的所有pattern，并以列表形式返回\n",
    "all_files = glob.glob(input_path)\n",
    "all_data = pd.DataFrame()\n",
    "\n",
    "# 循环遍历每个文件\n",
    "for file in all_files:\n",
    "    data_frame = pd.read_csv(file,\n",
    "                             usecols=[1,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21],\n",
    "                             index_col=None,\n",
    "                             encoding='gbk')\n",
    "    data = data_frame.iloc[0]\n",
    "\n",
    "    all_data = all_data.append(data)\n",
    "    # all_data.set_index('course_id',inplace = True)\n",
    "# print(all_data)\n",
    "all_data.to_csv('./model_input_data/avg_course_2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d07af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "input_path = './action_martix/mean_2_sort_course/*.csv'\n",
    "\n",
    "# glob.glob()函数将会匹配给定路径下的所有pattern，并以列表形式返回\n",
    "all_files = glob.glob(input_path)\n",
    "all_data = pd.DataFrame()\n",
    "\n",
    "# 循环遍历每个文件\n",
    "for file in all_files:\n",
    "    data_frame = pd.read_csv(file,\n",
    "                             usecols=[2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21],\n",
    "                             index_col=None,\n",
    "                             encoding='gbk')\n",
    "    data = data_frame.iloc[0]\n",
    "\n",
    "    all_data = all_data.append(data)\n",
    "    # all_data.set_index('course_id',inplace = True)\n",
    "# print(all_data)\n",
    "all_data.to_csv('./model_input_data/avg_user_2.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
